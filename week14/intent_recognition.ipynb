{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/it3103/blob/main/week15/intent_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTTt2on1Kdr-"
   },
   "source": [
    "# Intent Recognition\n",
    "\n",
    "In this practical, we will learn how to apply the HuggingFace Transformers library to our own Intent Recognition task for our chatbot.\n",
    "\n",
    "####**NOTE: Be sure to set your runtime to a GPU instance!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prPHVBopKx1O"
   },
   "source": [
    "## Install the Hugging Face Transformers Library\n",
    "\n",
    "Run the following cell below to install the transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXufUo5E0mfK"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eyUK96X91ud"
   },
   "source": [
    "## Getting the data and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MX2EMQRpl5kA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what is fare code h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what is booking class c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what does fare code q mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what is fare code qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what does the fare code f mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Label                             Text\n",
       "0  atis_abbreviation              what is fare code h\n",
       "1  atis_abbreviation          what is booking class c\n",
       "2  atis_abbreviation       what does fare code q mean\n",
       "3  atis_abbreviation             what is fare code qw\n",
       "4  atis_abbreviation   what does the fare code f mean"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_url = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/datasets/airchat_intents.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbViUOJL_B5m"
   },
   "source": [
    "We noticed that there are two columns 'Label' and 'Text'. Let's just examine what are the different labels we have and how many samples we have for each labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "flTF4DB-_Qee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atis_flight                                 3666\n",
       "atis_airfare                                 423\n",
       "atis_ground_service                          255\n",
       "atis_airline                                 157\n",
       "atis_abbreviation                            147\n",
       "atis_yes                                      82\n",
       "atis_aircraft                                 81\n",
       "atis_no                                       67\n",
       "atis_flight_time                              54\n",
       "atis_greeting                                 53\n",
       "atis_quantity                                 51\n",
       "atis_flight#atis_airfare                      21\n",
       "atis_distance                                 20\n",
       "atis_airport                                  20\n",
       "atis_city                                     19\n",
       "atis_ground_fare                              18\n",
       "atis_capacity                                 16\n",
       "atis_flight_no                                12\n",
       "atis_meal                                      6\n",
       "atis_restriction                               6\n",
       "atis_airline#atis_flight_no                    2\n",
       "atis_cheapest                                  1\n",
       "atis_aircraft#atis_flight#atis_flight_no       1\n",
       "atis_ground_service#atis_ground_fare           1\n",
       "atis_airfare#atis_flight_time                  1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCOUBlEr_cJ1"
   },
   "source": [
    "We can see that some labels have very few sample such as 'atis_meal', 'atis_airline#atis_flight_no', 'atis_cheapest', and so on. With so few samples, our model will have difficulty in learning any meaningful pattern from it. We will group these labels (with few samples) into a new label called 'others'.  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr6YP12kwOyD"
   },
   "source": [
    "### Re-define our Classification Labels\n",
    "\n",
    "Here we define the labels we are interested in classifying based on the original labels, and also we added a new label called 'Others'.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OdoYqzUQvnRt"
   },
   "outputs": [],
   "source": [
    "# Create a list of unique labels that we will recognize.\n",
    "#\n",
    "sentence_labels = [\n",
    "              \"others\",\n",
    "              \"atis_abbreviation\",\n",
    "              \"atis_aircraft\",\n",
    "              \"atis_airfare\",\n",
    "              \"atis_airline\",\n",
    "              \"atis_flight\",\n",
    "              \"atis_flight_time\",\n",
    "              \"atis_greeting\",\n",
    "              \"atis_ground_service\",\n",
    "              \"atis_quantity\",\n",
    "              \"atis_yes\",\n",
    "              \"atis_no\"]\n",
    "\n",
    "# This creates a reverse mapping dictionary of \"label\" -> index.\n",
    "# \n",
    "sentence_labels_id_by_label = dict((t, i) for i, t in enumerate(sentence_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51O9M5_4Aao3"
   },
   "source": [
    "Now we will map the previous labels to the few ones we specified in the cell above. We will also convert the text labels into numeric labels (e.g. others->0, atis_abbreviation->1, etc). We can use the `map()` function in dataframe to help us do that. We define a lambda function that do the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GmQkgwklnQ41"
   },
   "outputs": [],
   "source": [
    "df['Label'] = df['Label'].map(lambda label: \n",
    "                              sentence_labels_id_by_label[label] \n",
    "                              if label in sentence_labels_id_by_label \n",
    "                              else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z7KmBHB3A-DP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>5</td>\n",
       "      <td>what flights are available on wednesday from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>5</td>\n",
       "      <td>flights from pittsburgh to baltimore arriving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>5</td>\n",
       "      <td>all flights from boston to philadelphia which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>5</td>\n",
       "      <td>are there any flights from new york to los an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2</td>\n",
       "      <td>what kind of airplane is flight ua 281 from b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>5</td>\n",
       "      <td>what is the earliest flight from tampa to mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>5</td>\n",
       "      <td>i would like a flight between denver and san ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>5</td>\n",
       "      <td>newark to cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>5</td>\n",
       "      <td>please list all flights between boston and at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>8</td>\n",
       "      <td>is there ground transportation in st. louis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "1808      5   what flights are available on wednesday from ...\n",
       "2351      5   flights from pittsburgh to baltimore arriving...\n",
       "1316      5   all flights from boston to philadelphia which...\n",
       "3330      5   are there any flights from new york to los an...\n",
       "157       2   what kind of airplane is flight ua 281 from b...\n",
       "4059      5   what is the earliest flight from tampa to mil...\n",
       "1887      5   i would like a flight between denver and san ...\n",
       "3626      5                                newark to cleveland\n",
       "4510      5   please list all flights between boston and at...\n",
       "4947      8        is there ground transportation in st. louis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine a few random samples \n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXn8KmHAxc1l"
   },
   "source": [
    "### Split Our Data\n",
    "\n",
    "We will now separate the texts and labels and call them all_texts and all_labels and we will split the dataset into training and validation set. We do a stratified split to ensure we have equal representation of different labels in both train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eLTOzdnKB2Us"
   },
   "outputs": [],
   "source": [
    "all_texts = df['Text']\n",
    "all_labels = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EVyqTUPKxdOR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(all_texts, \n",
    "                                                                    all_labels, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xgKGYupJo59k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     0.707770\n",
       "3     0.081564\n",
       "8     0.049228\n",
       "4     0.030405\n",
       "1     0.028475\n",
       "0     0.027751\n",
       "2     0.015685\n",
       "10    0.015685\n",
       "11    0.013031\n",
       "6     0.010376\n",
       "7     0.010135\n",
       "9     0.009894\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts()/len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6UpZf9s2o_Xx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     0.707529\n",
       "3     0.082046\n",
       "8     0.049228\n",
       "4     0.029923\n",
       "1     0.027992\n",
       "0     0.027992\n",
       "10    0.016409\n",
       "2     0.015444\n",
       "11    0.012548\n",
       "6     0.010618\n",
       "7     0.010618\n",
       "9     0.009653\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels.value_counts()/len(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "milh-Q2-yZBe"
   },
   "source": [
    "### Tokenize the text \n",
    "\n",
    "Before we can use the text for classification, we need to tokenize them. We will use Tokenizer of the pretrained model 'distilbert-base-uncased' as we will be fine-tunining on a pretrained model 'distilbert-base-uncased'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5l_bBQ7dBc9V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q_8gIcR8yZJl"
   },
   "outputs": [],
   "source": [
    "## before we can feed the texts to tokenizer, we need to convert our texts into list of text string instead of \n",
    "## panda Series. We can do this by using to_list(). \n",
    "\n",
    "train_texts = train_texts.to_list()\n",
    "train_labels = train_labels.to_list()\n",
    "val_texts = val_texts.to_list()\n",
    "val_labels = val_labels.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xEDfpTUZqGBK"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CFpKNCpLp5n2"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_texts, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsO-EGFIDs7Z"
   },
   "source": [
    "Once we have the encodings, we will go ahead and create a tensorflow dataset, ready to be used to train our model. Since the HuggingFace pretrained model (the tensorflow version) is a Keras model, it can consume the tf.data dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cH9Bv9SKp9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 13:06:24.494115: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-05 13:06:24.494263: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (xps-markk): /proc/driver/nvidia/version does not exist\n",
      "2022-01-05 13:06:24.497016: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmAO-RI8y8fX"
   },
   "source": [
    "## Train Your Sentence Classification Model\n",
    "\n",
    "Run the following cell to download the \"distilbert-base-uncased\" and perform fine-tuning training using the dataset that we have above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2zgiouIb-Kpt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 13:06:32.058524: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_transform', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",num_labels=len(sentence_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5giXIw5Jnuq"
   },
   "source": [
    "As in previous lab, we start with a smaller learning rate 5e-5 (0.00005) and slowly reduce the learning rate over the course of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qWIOLntZ-l82"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Since our dataset is already batched, we can simply take the len.\n",
    "num_train_steps = len(train_dataset) * num_epochs\n",
    "\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Q39NhOmK-w9u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "259/259 [==============================] - 308s 1s/step - loss: 0.5422 - accuracy: 0.8627 - val_loss: 0.2009 - val_accuracy: 0.9488\n",
      "Epoch 2/2\n",
      "259/259 [==============================] - 312s 1s/step - loss: 0.1174 - accuracy: 0.9778 - val_loss: 0.1285 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a70404940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "opt = Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W60-n-I0TNX"
   },
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "Run the following code to evaluate our model with entire validation data set.\n",
    "\n",
    "We also print out the classification report to see how the model performs for each label. Note that those with smaller number of samples typically have lower F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UbLVVeCFuNku"
   },
   "outputs": [],
   "source": [
    "output = model.predict(val_dataset, batch_size=1)\n",
    "pred_probs = tf.nn.softmax(output.logits, axis=-1)\n",
    "preds = tf.argmax(pred_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "x73ytg7dIGvV"
   },
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for _, labels in val_dataset.as_numpy_iterator():\n",
    "    val_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nUt2HCZOufZN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.84        29\n",
      "           1       0.93      0.90      0.91        29\n",
      "           2       0.89      1.00      0.94        16\n",
      "           3       0.97      1.00      0.98        85\n",
      "           4       0.91      0.97      0.94        31\n",
      "           5       1.00      0.99      0.99       733\n",
      "           6       0.91      0.91      0.91        11\n",
      "           7       1.00      1.00      1.00        11\n",
      "           8       0.96      0.98      0.97        51\n",
      "           9       0.90      0.90      0.90        10\n",
      "          10       0.89      1.00      0.94        17\n",
      "          11       1.00      0.77      0.87        13\n",
      "\n",
      "    accuracy                           0.98      1036\n",
      "   macro avg       0.94      0.93      0.93      1036\n",
      "weighted avg       0.98      0.98      0.98      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(val_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT_ucCQv0FSG"
   },
   "source": [
    "### Saving the Model\n",
    "\n",
    "When you training has completed, run the following cell to save your model.\n",
    "\n",
    "Remember to download the model from Google Colab if you want to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1eV7zUC-A1Bu"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save_pretrained(\"intent_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9T_A7_F3OrR"
   },
   "source": [
    "## Putting Our Model to the Test\n",
    "\n",
    "Run the following cell to create the necessary classes and functions to load our model and perform inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9Dq45oOFH9Sc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at intent_model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at intent_model and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "#\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForSequenceClassification\n",
    ")\n",
    "\n",
    "# Create the DistilBERT tokenizer\n",
    "#\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Define a function to perform inference on a single input text.\n",
    "# \n",
    "def infer_intent(model, text):\n",
    "    # Passes the text into the tokenizer\n",
    "    #\n",
    "    input = tokenizer(text, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "    \n",
    "    # Sends the result from the tokenizer into our classification model\n",
    "    #\n",
    "    output = model(input)\n",
    "\n",
    "    # Extract the output logits and convert to softmax \n",
    "    # Find the classification index with the highest value.\n",
    "    #  \n",
    "    pred_label = tf.argmax(tf.nn.softmax(output.logits, axis=-1), axis=-1)\n",
    "\n",
    "    return pred_label\n",
    "\n",
    "# Create a list of unique labels that we will recognize.\n",
    "# Obviously this has to match what we trained our model with\n",
    "# earlier.\n",
    "#\n",
    "sentence_labels = [\n",
    "              \"others\",\n",
    "              \"atis_abbreviation\",\n",
    "              \"atis_aircraft\",\n",
    "              \"atis_airfare\",\n",
    "              \"atis_airline\",\n",
    "              \"atis_flight\",\n",
    "              \"atis_flight_time\",\n",
    "              \"atis_greeting\",\n",
    "              \"atis_ground_service\",\n",
    "              \"atis_quantity\",\n",
    "              \"atis_yes\",\n",
    "              \"atis_no\"]\n",
    "\n",
    "# Load the saved model file\n",
    "#\n",
    "intent_model = TFAutoModelForSequenceClassification.from_pretrained(\"intent_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "C3fouh-hMkEm"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hello this is me\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atis_greeting\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "\n",
    "print (sentence_labels[infer_intent(intent_model, text)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  adding: intent_model/ (stored 0%)\n",
      "  adding: intent_model/config.json (deflated 57%)\n",
      "  adding: intent_model/tf_model.h5 (deflated 8%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r intent_model.zip intent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "intent_recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
